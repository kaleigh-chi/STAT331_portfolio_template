---
title: "STAT 331 Portfolio"
author: "Kaleigh Chi"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be a A-.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, I provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. I also specified **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv}
# Lab 5, Revisiting Lab 2 (Revised)

library(tidyverse)
library(here)

surveys <- read_csv(here("STAT331", "Week 2", "Lab 2", "surveys.csv"))
```

-   `xlsx`

```{r wd-1-xlsx}
# Practice Activity 4, Data Import

library(readxl) 
library(tidyverse)


military <- read_xlsx(here::here("STAT331", 
                                 "Week 4", 
                                 "Practice Activity", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip = 7, 
                      n_max = 190)
```

-   `txt`

```{r wd-1-txt}
# PA 5.1: Regular Expressions, Setup

library(tidyverse)

message <- read_csv(here::here("STAT331", "Week 5", "PracticeActivity", "scrambled_message.txt"))
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2}
# Challenge 4, joining data with avocado data set

zillow <- zillow %>%
  pivot_longer(cols = `1/31/2015`:`9/30/2017`,
               names_to = "date",
               values_to = "prices") %>%
  select(region, date, prices) %>%
  separate(date, c("month", "day", "year"), sep = "/") %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month)
  ) %>%
  select(region, year, month, prices) %>%
  group_by(region, year, month) %>%
  summarise(meanHome = mean(prices))
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
# Lab 3, Problem 11 (revised)

hiphop_clean %>%
  filter(age < 20) %>%
  group_by(word) %>%
  summarise(Mean = mean(as.integer(familiarity))) %>%
  slice_max(Mean, n = 5)
```

-   character -- specifically a string

```{r wd-3-string}
# PA 5.1: Regular Expressions, Problem 3

str_subset(word, pattern = "z$")
```

-   factor

```{r wd-3-factor}
# Lab 3, Problem 13 (revised)

hiphop_clean %>%
  filter(age > 30, ethnic_cat == "white", sex == "Male", ) %>%
  group_by(word) %>%
  summarise(Mean = mean(as.integer(familiarity))) %>%
  slice_max(Mean, n = 5)
```

-   date

```{r wd-3-date}
# PA 5: Dates and Time, Problem 1

suspects <- suspects %>%
  filter(pm(Time.Spotted))
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
# Challenge 4, joining data with avocado data set

zillow <- zillow %>%
  pivot_longer(cols = `1/31/2015`:`9/30/2017`,
               names_to = "date",
               values_to = "prices") %>%
  select(region, date, prices) %>%
  separate(date, c("month", "day", "year"), sep = "/") %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month)
  ) %>%
  select(region, year, month, prices) %>%
  group_by(region, year, month) %>%
  summarise(meanHome = mean(prices))
```

-   character -- specifically a string

```{r wd-4-string}
# PA 5.1: Regular Expressions, Problem 3

message <- message %>%
  mutate(
    Word = str_remove_all(Word, pattern = "ugh+h(\\?|\\!)"),
    Word = str_remove_all(Word, pattern = "ugh(\\?|\\!|\\.)")
  )
```

-   factor

```{r wd-4-factor}
# Lab 3, Problem 5 (revised)

hiphop_clean <- hiphop |>
  mutate(
    across(c(jayz, jayz1, barkley, boondocks, boondocks1, monique, bieber), factor))
```

-   date

```{r wd-4-date}
# PA 5: Dates and Time, Problem 1

suspects <- suspects %>%
  mutate(Time.Spotted = ymd_hms(Time.Spotted),
         Time.Spotted = force_tz(Time.Spotted, 
                                 tzone = "America/Los_Angeles")
         )
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}
# Preview Activity 4

left_join(prof_info, prof_course)
```

-   `right_join()`

```{r wd-5-right}
# Preview Activity 4

right_join(prof_info, prof_course)
```

-   `inner_join()`

```{r wd-5-inner}
# Preview Activity 4

inner_join(prof_info, prof_course)
```

-   `full_join()`

```{r wd-5-full}
# Challenge 4, joining data with avocado data set

join_avocado <- full_join(zillow, 
                          avocado_cali, 
                          by = c("region", "month", "year")) %>%
  drop_na()
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
# Lab 4, Question 2 (Revised)

majorRegAvo <- avocado_clean %>%
  semi_join(majorRegion, by = "region") %>%
  filter(region != "TotalUS")
```

-   `anti_join()`

```{r wd-6-anti}
# Lab 4, Question 2 (Revised)

metroAvo <- avocado_clean %>%
  anti_join(majorRegion, by = "region") %>%
  anti_join(states, by = "region")
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r wd-7-long}
# Challenge 4, joining data with avocado data set

zillow <- zillow %>%
  pivot_longer(cols = `1/31/2015`:`9/30/2017`,
               names_to = "date",
               values_to = "prices") %>%
  select(region, date, prices) %>%
  separate(date, c("month", "day", "year"), sep = "/") %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month)
  ) %>%
  select(region, year, month, prices) %>%
  group_by(region, year, month) %>%
  summarise(meanHome = mean(prices))
```

-   `pivot_wider()`

```{r wd-7-wide}
# Lab 9, Problem 3.1 (Revised)

namesA %>%
  filter(Name == 'Allison') %>%
  rename(Sex = Gender) %>%
  group_by(Sex, State) %>%
  summarize(count_eval = sum(Count),
            .groups = "drop") %>%
  pivot_wider(names_from = Sex,
              values_from = count_eval,
              values_fill = 0)
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments: Lab 2, , Challenge 3, Challenge 4

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1}
# Challenge 2

ggplot(data = surveys,
       mapping = aes(x = weight,
                     y = species,
                     group = species,
                     color = genus)) +
  geom_boxplot(outlier.shape = NA) + 
  labs(x = "Weight of animals (grams)", 
       y = "Species of animal") +
  theme(legend.position="none") +
  theme_gray() +
  xlim(0, 400) +
  annotate("text", y = 1, x = 320, label = "Neotama") +
  annotate("text", y = 2, x = 125, label = "Chaetodipus") +
  annotate("text", y = 3, x = 110, label = "Peromyscus") +
  annotate("text", y = 4, x = 100, label = "Perognathus") +
  annotate("text", y = 5, x = 100, label = "Reithrodontomys") +
  annotate("text", y = 6, x = 180, label = "Sigmodon") +
  annotate("text", y = 7, x = 110, label = "Onychomys") +
  annotate("text", y = 8, x = 100, label = "Peromyscus") +
  annotate("text", y = 9, x = 100, label = "Reithrodontomys") +
  annotate("text", y = 10, x = 120, label = "Dipodomys") +
  annotate("text", y = 11, x = 130, label = "Dipodomys") +
  annotate("text", y = 12, x = 100, label = "Chaetodipus") +
  annotate("text", y = 13, x = 230, label = "Dipodomys") +
  annotate("text", y = 14, x = 80, label = "Onychomys")
```

-   Example 2

```{r r-2-2}
# Lab 4, Problem 7 (revised)

avocado_ca %>%
  select(c('small', 'large','xlarge', 'type', 'region')) %>%
  pivot_longer(small:xlarge,
               names_to = "avocadoSize",
               values_to = "avocadoSold") %>%
  group_by(region, avocadoSize, type) %>%
  summarise(avocado_sold = sum(avocadoSold)) %>%

  ggplot(mapping = aes(fill = avocadoSize,
                       x = region,
                       y = avocado_sold)) +
  geom_bar(position = "fill",
           stat = "identity") +
  scale_fill_manual(name = "Avocado Size", 
                    values = c("royalblue", "lightblue", "lightgreen")) +
  facet_grid(.~type) +
  labs(x = "Region of CA",
       y = "Proportion of Mean Avocados Sold") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) 

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}
# Lab 7, Problem 3.3

rescale_01 <- function(x) {
  stopifnot(is.numeric(x), length(x) > 1)

  max <- max(x, na.rm = TRUE)
  min <- min(x, na.rm = TRUE)

  x <- ((x - min) / (max - min))
  return(x)
}
```

-   Example 2

```{r r-3-2}
# Lab 3, Problem 13 (Revised)

hiphop_clean %>%
  filter(age > 30, ethnic_cat == "white", sex == "Male", ) %>%
  group_by(word) %>%
  summarise(Mean = mean(as.integer(familiarity))) %>%
  slice_max(Mean, n = 5)
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
# Lab 2, Problem 7

ggplot(data = surveys) +
  geom_jitter(mapping = aes(x = weight, 
                            y = hindfoot_length)) +
  facet_wrap(~ species)
```

-   numeric variables and categorical variables

```{r dvs-1-num-cat}
# Lab 5, Problem 5 (Revised)

metroAvo %>%
  semi_join(top5, by = "region") %>%
  ggplot(mapping = aes(x = `Total Volume`, y  = region, fill = region)) +
  geom_boxplot() +
  scale_fill_manual(values = c("cadetblue", "darkseagreen", "lavender", "khaki", "paleturquoise")) +
  scale_x_continuous(labels = scales::comma) + 
  theme_light() + 
  labs(y = "Metro Region", 
       x = "Total Volume of Avocados Sold", 
       fill = "Metro Region", 
       title = "Avocados Sold by the Top 5 Avocado Selling Metro Regions in the US") +
  theme(legend.position = "none")
```

-   categorical variables

```{r dvs-1-cat}
# Lab 7, Problem 2.2

blackFootFish %>%
  filter(is.na(weight)) %>%
  mutate(
    trip = factor(trip, 
                  levels = c(1,2), 
                  labels = c("Trip 1", "Trip 2")),
    year = factor(year)
  ) %>%
  
  ggplot(aes(x = year, fill = trip)) +
    geom_bar(position = "stack") +
    facet_wrap(. ~ section) +
    labs(y = NULL,
         x = "Year",
         title = "Frequency of Missing Data Across Different River Sections from 1989 to 2006",
         fill = "Trips") +
    scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
    scale_fill_manual(values = c("darkorange", "darkturquoise")) +
    theme(plot.title.position = "plot") 
```

-   dates

```{r dvs-1-date}
# Lab 5, Time Series Plot - Problem 4 (Revised)

ggplot(data = mean_weight_vary, 
       aes(x = year, 
           y = mean_weight, 
           col = fct_reorder2(genus, year, mean_weight))) +
  geom_line() +
  labs(x = "Year", 
       y = NULL,
       title = "Average Genus Weight Variation throughout Duration of Study",
       col = "Genus") +
  theme_light() +
  theme(plot.title.position = "plot")
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
# Lab 7, Problem 2.2

blackFootFish %>%
  filter(is.na(weight)) %>%
  mutate(
    trip = factor(trip, 
                  levels = c(1,2), 
                  labels = c("Trip 1", "Trip 2")),
    year = factor(year)
  ) %>%
  
  ggplot(aes(x = year, fill = trip)) +
    geom_bar(position = "stack") +
    facet_wrap(. ~ section) +
    labs(y = NULL,
         x = "Year",
         title = "Frequency of Missing Data Across Different River Sections from 1989 to 2006",
         fill = "Trips") +
    scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
    scale_fill_manual(values = c("darkorange", "darkturquoise")) +
    theme(plot.title.position = "plot") 
```

-   Example 2

```{r dvs-2-2}
# Lab 4, Problem 6 (revised)

avocado_ca %>%
  group_by(region, type) %>%
  summarize(mean = mean(AveragePrice)) %>%
  ggplot(mapping = aes(x = region, y = mean, label = round(mean, 2))) +
  geom_line(mapping = aes(group = region)) +
  geom_point(mapping = aes(color = type)) +
  geom_text(aes(color = type), size = 2, hjust = 1.5) +
  theme_light() +
  labs(x = "CA Regions", 
       y = "Conventional vs Organic Avocado Price Differences", 
       title = "Avocado Price Differences in 4 Major California Regions",
       color = "Avocado Type")
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}
# Lab 4, Problem 5 (revised)

metroAvo %>%
  semi_join(top5, by = "region") %>%
  ggplot(mapping = aes(x = `Total Volume`, y  = region, fill = region)) +
  geom_boxplot() +
  scale_fill_manual(values = c("cadetblue", "darkseagreen", "lavender", "khaki", "paleturquoise")) +
  scale_x_continuous(labels = scales::comma) + 
  theme_light() + 
  labs(y = "Metro Region", 
       x = "Total Volume of Avocados Sold", 
       fill = "Metro Region", 
       title = "Avocados Sold by the Top 5 Avocado Selling Metro Regions in the US") +
  theme(legend.position = "none")
```

-   Example 2

```{r dvs-3-2}
# Challenge 4, Avocado vs Housing Prices Plot

# Lab 7, Problem 2.2

blackFootFish %>%
  filter(is.na(weight)) %>%
  mutate(
    trip = factor(trip, 
                  levels = c(1,2), 
                  labels = c("Trip 1", "Trip 2")),
    year = factor(year)
  ) %>%
  
  ggplot(aes(x = year, fill = trip)) +
    geom_bar(position = "stack") +
    facet_wrap(. ~ section) +
    labs(y = NULL,
         x = "Year",
         title = "Frequency of Missing Data Across Different River Sections from 1989 to 2006",
         fill = "Trips") +
    scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
    scale_fill_manual(values = c("darkorange", "darkturquoise")) +
    theme(plot.title.position = "plot") 
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
# Challenge 3, Comparing Male vs Female

hiphop_mean <- hiphop %>%
  group_by(sex) %>%
  summarize(across(intl:unclassifiable, ~mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = "intl":"unclassifiable")
```

-   Example 2

```{r dvs-4-2}
# Lab 4, Problem 5 (Revised)

top5 <- metroAvo %>%
  group_by(region) %>%
  summarize(mean_total_volume = mean(`Total Volume`)) %>%
  slice_max(mean_total_volume, 
            n = 5)
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
# Lab 7, Problem 2.1 

blackFootFish %>%
  summarise(
    across(
      .cols = trip:species, 
      .fns = ~sum(is.na(.x))
      )
    )
```

-   Example 2

```{r dvs-5-2}
# Challenge 3, Comparing Male vs Female

hiphop_mean <- hiphop %>%
  group_by(sex) %>%
  summarize(across(intl:unclassifiable, ~mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = "intl":"unclassifiable")
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}
# Challenge 9, Problem 10 (Revised)
namesA %>%
  filter(Name %in% c("Allan", "Allen", "Alan"),
         State %in% c("CA", "PA"),
         Year == 2000,
         Gender == "M") %>%
  group_by(State) %>%
  mutate(Prop = Count / sum(Count)) %>%
  select(-Count, -Year, -Gender) %>%
  pivot_wider(names_from = Name,
              values_from = Prop,
              values_fill = 0) %>%
  gt(groupname_col = "State") %>%
  fmt_percent(columns = 2:4, decimals = 2) %>%
  tab_header(title = "Percentage of Baby 'Alan' Variations Within States",
             subtitle = "California and Pennsylvania in Year 2000") %>%
  tab_options(heading.title.font.size = 20,
              table.background.color = "steelblue",
              heading.align = "left")
```

-   Example 2

```{r dvs-6-2}
# Challenge 9, Problem 9 (Revised)

namesA %>%
  filter(Name %in% c("Allan", "Allen", "Alan"),
         State %in% c("CA", "PA"), 
         Year == 2000, 
         Gender == "M") %>%
  group_by(Name, State) %>%
  summarise(Count = sum(Count), .groups = 'keep') %>%
  pivot_wider(names_from = Name,
              values_from = Count,
              values_fill = 0) %>%
  gt() %>%
  cols_label(State = "State") %>%
  tab_header(title = "Frequency of Baby 'Alan' Variations",
             subtitle = "California and Pennsyvlania in Year 2000")
```

**DVS-7: I show creativity in my tables.**

-   Example 1 ( needs to come from challenge 9)

```{r dvs-7-1}
# Challenge 9, Problem 10 (Revised)

namesA %>%
  filter(Name %in% c("Allan", "Allen", "Alan"),
         State %in% c("CA", "PA"),
         Year == 2000,
         Gender == "M") %>%
  group_by(State) %>%
  mutate(Prop = Count / sum(Count)) %>%
  select(-Count, -Year, -Gender) %>%
  pivot_wider(names_from = Name,
              values_from = Prop,
              values_fill = 0) %>%
  gt(groupname_col = "State") %>%
  fmt_percent(columns = 2:4, decimals = 2) %>%
  tab_header(title = "Percentage of Baby 'Alan' Variations Within States",
             subtitle = "California and Pennsylvania in Year 2000") %>%
  tab_options(heading.title.font.size = 20,
              table.background.color = "steelblue",
              heading.align = "left")
```

-   Example 2

```{r dvs-7-2}
# Challenge 9, Problem 1 (Revised)

namesA %>%
  filter(Name == 'Allison') %>%
  rename(Sex = Gender) %>%
  group_by(Sex, State) %>%
  summarize(count_eval = sum(Count),
            .groups = "drop") %>%
  pivot_wider(names_from = Sex,
              values_from = count_eval,
              values_fill = 0) %>%
  gt() %>%
  as.data.frame() %>%
  datatable() 
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
# Lab 7, Problem 3.4

scaleFish <- blackFootFish %>%
  mutate(lengthRescale = rescale_01(length)) 

ggplot(data = scaleFish, aes(x = lengthRescale)) +
  geom_density()
```

-   `across()`

```{r pe-1-across}
# Challenge 3, Comparing Male vs Female

hiphop_mean <- hiphop %>%
  group_by(sex) %>%
  summarize(across(intl:unclassifiable, ~mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = "intl":"unclassifiable")
```

-   `map()` functions

```{r pe-1-map-1}
# Lab 8, Step 4 (Revised)

christmas_song <- function(dataset, line, phrase_col) {
  
  song <- map_chr(.x = 1:line,
                  .f = ~sing_day(dataset, .x, phrase_col))
  
  return(glue::glue("{song}"))
}

christmas_song(xmas2, 12, "Full.Phrase")
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}
# Lab 8, Step 4 (Revised)

christmas_song <- function(dataset, line, phrase_col) {
  
  song <- map_chr(.x = 1:line,
                  .f = ~sing_day(dataset, .x, phrase_col))
  
  return(glue::glue("{song}"))
}

christmas_song(xmas2, 12, "Full.Phrase")

```

-   Example 2

```{r pe2-2}
# Lab 7, Problem 3.1 

rescale_01 <- function(x) {
  stopifnot(is.numeric(x), length(x) > 1)

  max <- max(x, na.rm = TRUE)
  min <- min(x, na.rm = TRUE)

  x <- ((x - min) / (max - min))
  return(x)
}
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}
# Challenge 3, Comparing Male vs Female

hiphop_mean <- hiphop %>%
  group_by(sex) %>%
  summarize(across(intl:unclassifiable, ~mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = "intl":"unclassifiable")
```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}
# Lab 8, Step 4 (Revised)

christmas_song <- function(dataset, line, phrase_col) {
  
  song <- map_chr(.x = 1:line,
                  .f = ~sing_day(dataset, .x, phrase_col))
  
  return(glue::glue("{song}"))
}

christmas_song(xmas2, 12, "Full.Phrase")
```

```{r pe-3-map-2}
# Lab 8, 0.1 Step 2 (Revised)

xmas2 <- xmas %>%
 mutate(Full.Phrase = pmap_chr(.l = list(Day, 
                                         Day.in.Words, 
                                         Gift.Item, 
                                         Verb, 
                                         Adjective, 
                                         Location),
                               .f = make_phrase))
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1

```{r pe-4-1}
# Lab 3, Problem 11 (revised)

hiphop_clean %>%
  filter(age < 20) %>%
  group_by(word) %>%
  summarise(Mean = mean(as.integer(familiarity))) %>%
  slice_max(Mean, n = 5)
hiphop_clean %>%
  filter(age < 20) %>%
  group_by(word) %>%
  summarise(Mean = mean(as.integer(familiarity))) %>%
  slice_min(Mean, n = 5)
```

-   Example 2

```{r pe-4-2}
# Challenge 3, Comparing Male vs Female

hiphop_mean <- hiphop %>%
  group_by(sex) %>%
  summarize(across(intl:unclassifiable, ~mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = "intl":"unclassifiable")
```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}
# Practice Activity 9.2, Warmup

qunif(0.95, min = 1.5, max = 3.5)

qnorm(0.1, mean = 4.6, sd = 0.8)

pnorm(5, mean = 4.6, sd = 0.8, lower.tail = FALSE)

pchisq(5, df = 4, lower.tail = FALSE)

sum(rnorm(100, mean = 4.6, sd = 0.8) < 4)
```

-   Example 2

```{r dsm-1-2}
# Practice Activity 9.2, Catching a Con

set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = 0.8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(trombones, cornets, reeds))
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, 
                                       n_cor = 110, 
                                       n_reed = 1035)
                      )

sum(my_weights < 4532)
```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1 ( these need to come from either practice activity 9.1 or lab 9)

```{r dsm-2-1}
# Lab 9, Problem 5 (Revised)

estReg <- allison_f |>
  lm(F ~ Year, data = _)
```

-   Example 2

```{r dsm-2-2}
# Practice Activity 9.1

modMys <- mystery |>
  lm(weight_before ~ weight_after, data = _)
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

I think I revised my thinking throughout this course by restructuring my approach to make code more user friendly. It's easy to make a code block run and carry out tasks, but it takes extra effort to make code more tidy by adding spaces and hitting enter after certain characters. Additionally, efficiency isn't something I was concerned about but condensing code to save a couple lines allows the computer to process the block faster. These were things I never really thought about that I've been growing on. When I move forward to my career or working with teams, I can't present messy or inefficient code because it's hard for people to read and makes work more inefficient.

Based on the code examples I've provided in my portfolio, I've revised my thinking by structuring my R code blocks cleanly and adding features, especially to my visualization, that makes my outputs more user friendly. When it comes to revising my thinking, I take into consideration the feedback given back to me from my peers and the feedback I am given from Dr. Theobold.

I went through and heavily edited multiple labs where I believe I now have mastered the skills of. I think the greatest way to prove growth is to tackle the assignment that was the hardest for myself. In particular, I'm submitting lab 4 as my portfolio revision because it had the most extensive feedback and errors. I didn't want to walk away from this class without proving that I knew filtering joins() and I also know how crucial the concept of joins is in SQL - a skill I aim to develop as well.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I extended my thinking throughout this course by doing my own research and outsourcing R tricks to make my visualizations and code more clean and efficient. I've created comments in the original Quarto files that cited my sources for the code examples I've provided in this portfolio. Examples of also stepping up extending my thinking is in challenge 2 when I choose a more difficult level, or I tried spicing up my visualizations like in lab 4 and lab 7.

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->

![This is a Peer Review that I am proud of. I put a lot of thought into this review in regard to how tidy and efficient their code was. I made sure to follow the rubric and cited specific spots where I thought they did well.](images/PeerReview.JPG){fig-align="center"}

![Another peer interaction I'm proud of. I'm stepping up from my interaction level on Discord from week 6, and I'm giving useful comments.](images/image-1142099365.png)

The screenshots above are examples of peer reviews I am proud of. I believe I have grown as a reviewer to give more thorough checks of my classmate's codes and even cite where in their code I am proud of or I believe needs improvement. When I started off this quarter I wasn't giving my feedback the most timely because I was up against the clock. I've been giving my reviews in a timely manner which I am proud of. I believe I take my reviews seriously and it's important for me to provide feedback constructively where I can help someone improve without being discouraging.

In regards to group collaboration, I feel that I am always engaged with group work. My role thus far has always been the person supporting the drivers. I have my laptop on the side to search up anything the drivers need help on or read instructions. I have never overstepped my role of taking control of other's keyboards or seat. I am also committed to the assignments in class. An example of this is when my groupmate and I set up a Zoom meeting to finish a Practice Activity because we were not on campus during a time we were both free.

Previously in my midterm portfolio, I said that I thought I lacked my interaction on Discord. I think I took steps to answer more questions and engage with my classmate's questions because I realized I needed to step up in that aspect.
